{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e86a0d",
   "metadata": {},
   "source": [
    "# Quick Start Guide - Azure AI Foundry\n",
    "\n",
    "This notebook provides a hands-on introduction to Azure AI Foundry. You'll learn how to:\n",
    "1. Initialize the AI Project client\n",
    "2. List available models\n",
    "3. Create a simple completion request\n",
    "4. Handle basic error scenarios\n",
    "\n",
    "## Prerequisites\n",
    "- Completed environment setup from previous notebook\n",
    "- Azure credentials configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a355de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize credentials\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18d4ef",
   "metadata": {},
   "source": [
    "## Initialize AI Project Client\n",
    "\n",
    "> **Note:** Before proceeding, ensure you:\n",
    "> 1. Copy your `.env.local` file to `.env`\n",
    "> 2. Update the project connection string in your `.env` file\n",
    "> 3. Have a Hub and Project already provisioned in Azure AI Foundry\n",
    "\n",
    "You can find your project connection string in [Azure AI Foundry](https://ai.azure.com) under your project's settings:\n",
    "\n",
    "<img src=\"proj-conn-string.png\" alt=\"Project Connection String Location\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b96006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Create AI Project client\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    client = AIProjectClient.from_connection_string(\n",
    "        conn_str=os.getenv(\"PROJECT_CONNECTION_STRING\"),\n",
    "        credential=credential\n",
    "    )\n",
    "    print(\"✓ Successfully initialized AIProjectClient\")\n",
    "except Exception as e:\n",
    "    print(f\"× Error initializing client: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77e602",
   "metadata": {},
   "source": [
    "## Create a Simple Completion\n",
    "Let's try a basic completion request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.models import UserMessage\n",
    "\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "try:\n",
    "    chat_client = client.inference.get_chat_completions_client()\n",
    "    response = chat_client.complete(\n",
    "        model=model_deployment_name, \n",
    "        messages=[UserMessage(content=\"How to be healthy in one sentence?\")]\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7864f9",
   "metadata": {},
   "source": [
    "## Create a simple Agent\n",
    "\n",
    "Using AI Agent Service, we can create a simple agent to answer health related questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import CodeInterpreterTool\n",
    "\n",
    "try:\n",
    "    # Create an agent with code interpreter\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "    agent = client.agents.create_agent(\n",
    "        model=model_deployment_name,\n",
    "        name=\"bmi-calculator\",\n",
    "        instructions=\"You are a health analyst who calculates BMI using US metrics (pounds, feet/inches). Use average US male measurements: 5'9\\\" (69 inches) and 198 pounds. Create a visualization showing where this BMI falls on the scale.\",\n",
    "        tools=code_interpreter.definitions,\n",
    "        tool_resources=code_interpreter.resources,\n",
    "    )\n",
    "    \n",
    "    thread = client.agents.create_thread()\n",
    "    \n",
    "    # Request BMI analysis\n",
    "    message = client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"Calculate BMI for an average US male (5'9\\\", 198 lbs). Create a visualization showing where this BMI falls on the standard BMI scale from 15 to 35. Include the standard BMI categories (Underweight, Normal, Overweight, Obese) in the visualization.\"\n",
    "    )\n",
    "    \n",
    "    # Process the request\n",
    "    run = client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    \n",
    "    # Get and save any visualizations\n",
    "    messages = client.agents.list_messages(thread_id=thread.id)\n",
    "    for image_content in messages.image_contents:\n",
    "        file_name = f\"bmi_analysis_{image_content.image_file.file_id}.png\"\n",
    "        client.agents.save_file(file_id=image_content.image_file.file_id, file_name=file_name)\n",
    "        print(f\"Analysis saved as: {file_name}\")\n",
    "    \n",
    "    # Print the analysis\n",
    "    if last_msg := messages.get_last_text_message_by_sender(\"assistant\"):\n",
    "        print(f\"Analysis: {last_msg.text.value}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    client.agents.delete_agent(agent.id)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e98675a",
   "metadata": {},
   "source": [
    "## Error Handling Example\n",
    "Let's see how to handle a common error scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error handling\n",
    "try:\n",
    "    # Intentionally use invalid deployment name\n",
    "    response = client.models.generate(\n",
    "        deployment_name=\"non-existent-model\",\n",
    "        prompt=\"This should fail gracefully\",\n",
    "        max_tokens=100\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Expected error caught successfully:\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error message: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e255f",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Explore more advanced model configurations\n",
    "- Try different prompt types\n",
    "- Implement retry logic for robustness\n",
    "- Add logging for production use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
